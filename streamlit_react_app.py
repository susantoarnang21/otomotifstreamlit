# -*- coding: utf-8 -*-
"""streamlit_react_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wmchp9jgZketGh5NseKRKW-kATLwIGDK

# ğŸ’¬ LangGraph ReAct Chatbot (Colab Version)
Notebook ini merupakan konversi dari aplikasi Streamlit `streamlit_react_app.py`. Anda dapat menjalankannya di Google Colab untuk menguji fungsi chatbot menggunakan LangChain dan Google Gemini API.

---
### Petunjuk:
1. Jalankan setiap cell secara berurutan.
2. Masukkan API Key Google Anda pada bagian input.
3. Interaksi dengan chatbot akan ditampilkan langsung di output notebook.
"""

!pip install langchain-google-genai langgraph streamlit langchain-core

# Import the necessary libraries
import streamlit as st  # For creating the web app interface
from langchain_google_genai import ChatGoogleGenerativeAI  # For interacting with Google Gemini via LangChain
from langgraph.prebuilt import create_react_agent  # For creating a ReAct agent
from langchain_core.messages import HumanMessage, AIMessage  # For message formatting

# --- 1. Page Configuration and Title ---

# Set the title and a caption for the web page
st.title("ğŸ’¬ LangGraph ReAct Chatbot")
st.caption("A simple and friendly chat using LangGraph with Google's Gemini model")

# --- 2. Sidebar for Settings ---

# Create a sidebar section for app settings using 'with st.sidebar:'
with st.sidebar:
    # Add a subheader to organize the settings
    st.subheader("Settings")

    # Create a text input field for the Google AI API Key.
    # 'type="password"' hides the key as the user types it.
    google_api_key = st.text_input("Google AI API Key", type="password")

    # Create a button to reset the conversation.
    # 'help' provides a tooltip that appears when hovering over the button.
    reset_button = st.button("Reset Conversation", help="Clear all messages and start fresh")

# --- 3. API Key and Agent Initialization ---

# Check if the user has provided an API key.
# If not, display an informational message and stop the app from running further.
if not google_api_key:
    st.info("Please add your Google AI API key in the sidebar to start chatting.", icon="ğŸ—ï¸")
    st.stop()

# This block of code handles the creation of the LangGraph agent.
# It's designed to be efficient: it only creates a new agent if one doesn't exist
# or if the user has changed the API key in the sidebar.

# We use `st.session_state` which is Streamlit's way of "remembering" variables
# between user interactions (like sending a message or clicking a button).
if ("agent" not in st.session_state) or (getattr(st.session_state, "_last_key", None) != google_api_key):
    try:
        # Initialize the LLM with the API key
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            google_api_key=google_api_key,
            temperature=0.7
        )

        # Create a simple ReAct agent with the LLM
        st.session_state.agent = create_react_agent(
            model=llm,
            tools=[],  # No tools for this simple example
            prompt="You are a helpful, friendly assistant. Respond concisely and clearly."
        )

        # Store the new key in session state to compare against later.
        st.session_state._last_key = google_api_key
        # Since the key changed, we must clear the old message history.
        st.session_state.pop("messages", None)
    except Exception as e:
        # If the key is invalid, show an error and stop.
        st.error(f"Invalid API Key or configuration error: {e}")
        st.stop()

# --- 4. Chat History Management ---

# Initialize the message history (as a list) if it doesn't exist.
if "messages" not in st.session_state:
    st.session_state.messages = []

# Handle the reset button click.
if reset_button:
    # If the reset button is clicked, clear the agent and message history from memory.
    st.session_state.pop("agent", None)
    st.session_state.pop("messages", None)
    # st.rerun() tells Streamlit to refresh the page from the top.
    st.rerun()

# --- 5. Display Past Messages ---

# Loop through every message currently stored in the session state.
for msg in st.session_state.messages:
    # For each message, create a chat message bubble with the appropriate role ("user" or "assistant").
    with st.chat_message(msg["role"]):
        # Display the content of the message using Markdown for nice formatting.
        st.markdown(msg["content"])

# --- 6. Handle User Input and Agent Communication ---

# Create a chat input box at the bottom of the page.
# The user's typed message will be stored in the 'prompt' variable.
prompt = st.chat_input("Type your message here...")

# Check if the user has entered a message.
if prompt:
    # 1. Add the user's message to our message history list.
    st.session_state.messages.append({"role": "user", "content": prompt})
    # 2. Display the user's message on the screen immediately for a responsive feel.
    with st.chat_message("user"):
        st.markdown(prompt)

    # 3. Get the assistant's response.
    # Use a 'try...except' block to gracefully handle potential errors (e.g., network issues, API errors).
    try:
        # Convert the message history to the format expected by the agent
        messages = []
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                messages.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                messages.append(AIMessage(content=msg["content"]))

        # Send the user's prompt to the agent
        response = st.session_state.agent.invoke({"messages": messages})

        # Extract the answer from the response
        if "messages" in response and len(response["messages"]) > 0:
            answer = response["messages"][-1].content
        else:
            answer = "I'm sorry, I couldn't generate a response."

    except Exception as e:
        # If any error occurs, create an error message to display to the user.
        answer = f"An error occurred: {e}"

    # 4. Display the assistant's response.
    with st.chat_message("assistant"):
        st.markdown(answer)
    # 5. Add the assistant's response to the message history list.
    st.session_state.messages.append({"role": "assistant", "content": answer})

# --- CONFIGURASI APLIKASI ---
st.set_page_config(page_title="ğŸš— GAIKINDO Sales Chatbot", page_icon="ğŸ¤–", layout="wide")

st.markdown("""
    <style>
    /* ========== CUSTOM CHAT STYLE ========== */
    .stChatMessage {
        border-radius: 15px !important;
        padding: 10px 15px !important;
        margin-bottom: 10px !important;
        animation: fadeIn 0.3s ease-in-out;
    }
    .stChatMessage[data-testid="user-avatar"] + div div {
        background-color: #DCF8C6 !important;  /* hijau muda seperti WhatsApp */
        color: black !important;
        border-radius: 15px 15px 0 15px !important;
    }
    .stChatMessage[data-testid="assistant-avatar"] + div div {
        background-color: #F1F0F0 !important;  /* abu lembut untuk AI */
        color: #333 !important;
        border-radius: 15px 15px 15px 0 !important;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(5px); }
        to { opacity: 1; transform: translateY(0); }
    }
    /* Judul & warna */
    .title {
        font-size: 28px;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 10px;
    }
    .subtitle {
        text-align: center;
        font-size: 16px;
        color: gray;
        margin-bottom: 30px;
    }
    </style>
""", unsafe_allow_html=True)

# Judul halaman
st.markdown('<div class="title">ğŸš— GAIKINDO Sales Insight Chatbot</div>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">Chat dengan data wholesales & retail otomotif Indonesia (2023â€“2025)</div>', unsafe_allow_html=True)

# --- SIDEBAR ---
with st.sidebar:
    st.header("âš™ï¸ Pengaturan")
    google_api_key = st.text_input("ğŸ”‘ Masukkan Google API Key", type="password")
    uploaded_files = st.file_uploader(
        "ğŸ“ Unggah file PDF GAIKINDO", type=["pdf"], accept_multiple_files=True
    )
    build_index = st.button("ğŸš€ Bangun Database Informasi")
    reset_chat = st.button("ğŸ§¹ Reset Chat")

# --- STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "chain" not in st.session_state:
    st.session_state.chain = None

if reset_chat:
    st.session_state.messages = []
    st.session_state.chain = None
    st.rerun()

# --- PROSES BANGUN DATABASE PDF ---
if build_index:
    if not google_api_key:
        st.error("Masukkan API key terlebih dahulu âš ï¸")
        st.stop()

    if not uploaded_files:
        st.warning("Unggah minimal satu file PDF ğŸ“„")
        st.stop()

    st.info("â³ Sedang memproses dokumen... Harap tunggu sebentar.")
    all_docs = []
    for file in uploaded_files:
        loader = PyPDFLoader(file)
        docs = loader.load()
        all_docs.extend(docs)

    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    split_docs = splitter.split_documents(all_docs)

    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001", google_api_key=google_api_key
    )
    vectorstore = FAISS.from_documents(split_docs, embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=google_api_key)
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    st.session_state.chain = ConversationalRetrievalChain.from_llm(
        llm=llm, retriever=retriever, memory=memory
    )
    st.success("âœ… Database PDF GAIKINDO berhasil dibuat!")

# --- TAMPILKAN CHAT HISTORY ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- INPUT CHAT ---
prompt = st.chat_input("ğŸ’¬ Ketik pertanyaan Anda tentang data GAIKINDO...")

if prompt:
    if not st.session_state.chain:
        st.warning("Bangun database terlebih dahulu sebelum chatting ğŸ§ ")
        st.stop()

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        response = st.session_state.chain({"question": prompt})
        answer = response["answer"]
    except Exception as e:
        answer = f"âŒ Terjadi kesalahan: {e}"

    with st.chat_message("assistant"):
        st.markdown(answer)
    st.session_state.messages.append({"role": "assistant", "content": answer})